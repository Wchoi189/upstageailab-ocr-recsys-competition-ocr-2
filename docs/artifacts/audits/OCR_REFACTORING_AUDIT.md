# OCR Directory Refactoring Audit & Proposal

**Date:** 2025-12-23
**Auditor:** Claude
**Purpose:** Identify refactoring opportunities, high-risk areas, and architectural improvements in the OCR pipeline

---

## Executive Summary

The `ocr/` directory contains **30,297 lines** of Python code across **167 files** organized into **29 subdirectories**. The codebase demonstrates **good overall architecture** with strong component separation and modular design. However, it suffers from **scattered concerns** in critical areas that create maintenance burden and increase bug surface area.

**Key Findings:**
- üî¥ **CRITICAL:** Preprocessing module is fragmented (28 files, 8273 LOC) - needs consolidation
- üî¥ **CRITICAL:** Coordinate transformation logic duplicated across 5+ files - high bug risk
- üü° **HIGH:** Data validation scattered across 3 separate modules
- üü° **HIGH:** Extreme nesting depth (up to 9 levels) in performance-critical code
- üü¢ **GOOD:** Component registry pattern enables clean experimentation
- üü¢ **GOOD:** Pipeline orchestration is well-structured

**Overall Health: üü° MODERATE** (72/100)
- Good modularity, but scattered concerns need consolidation

---

## Codebase Statistics

| Metric | Value | Assessment |
|--------|-------|-----------|
| **Total Lines** | 30,297 LOC | MODERATE (well-scoped) |
| **Files** | 167 files | MODERATE (good modularization) |
| **Directories** | 29 subdirs | GOOD (logical organization) |
| **Avg File Size** | 181 LOC | GOOD (not too large) |
| **Largest File** | `datasets/base.py` (896 LOC) | ACCEPTABLE |
| **Max Nesting Depth** | 9 levels | üî¥ CRITICAL (too complex) |
| **Wildcard Imports** | 0 | ‚úÖ EXCELLENT |
| **Circular Dependencies** | 0 detected | ‚úÖ EXCELLENT |

---

## Critical Issues (Priority 1 - Address Immediately)

### üî¥ CRITICAL #1: Preprocessing Pipeline Fragmentation

**Impact:** HIGH - Maintenance burden, unclear composition, code duplication
**Files Affected:** 28 files, 8,273 lines of code
**Location:** `ocr/datasets/preprocessing/`

#### Problem Description

The preprocessing module has exploded into 28 separate files with **4 different pipeline implementations**:

```
preprocessing/
‚îú‚îÄ‚îÄ pipeline.py (383 LOC)                        # DocumentPreprocessor (legacy)
‚îú‚îÄ‚îÄ advanced_preprocessor.py (373 LOC)           # AdvancedDocumentPreprocessor
‚îú‚îÄ‚îÄ enhanced_pipeline.py (447 LOC)               # EnhancedPipeline (alternative)
‚îú‚îÄ‚îÄ advanced_detector.py (661 LOC)               # Advanced detection strategies
‚îú‚îÄ‚îÄ document_flattening.py (655 LOC)             # Perspective warping
‚îú‚îÄ‚îÄ intelligent_brightness.py (470 LOC)          # Brightness normalization
‚îú‚îÄ‚îÄ advanced_noise_elimination.py (440 LOC)      # Noise reduction
‚îú‚îÄ‚îÄ detector.py (473 LOC)                        # Basic document detection
‚îú‚îÄ‚îÄ high_confidence_decision_making.py (475 LOC) # Multi-hypothesis fusion
‚îú‚îÄ‚îÄ phase1_validation_framework.py (526 LOC)     # Validation logic
‚îú‚îÄ‚îÄ geometry_validation.py (329 LOC)             # Geometric checks
‚îú‚îÄ‚îÄ corner_selection.py (324 LOC)                # 9 NESTING LEVELS ‚ö†Ô∏è
‚îú‚îÄ‚îÄ validators.py (381 LOC)                      # Input validation
‚îú‚îÄ‚îÄ geometric_document_modeling.py               # RANSAC modeling
‚îú‚îÄ‚îÄ perspective.py                               # Perspective correction
‚îú‚îÄ‚îÄ advanced_detector_test.py (405 LOC)          # Test utilities
‚îî‚îÄ‚îÄ [14 more specialized modules...]
```

#### Why This Is Critical

1. **Unclear Composition:** Users cannot determine which preprocessing steps are actually used
2. **Multiple Implementations:** 4 different pipelines (DocumentPreprocessor, AdvancedDocumentPreprocessor, EnhancedPipeline, LensStylePreprocessor)
3. **Code Duplication:** Similar detection/validation logic across multiple files
4. **High Interdependency:** Complex cross-imports between detection strategies
5. **Scattered Responsibilities:** Each preprocessing step is isolated, making the overall flow unclear

#### Recommended Solution

**CONSOLIDATE into composable pipeline architecture:**

```python
# Proposed structure:
ocr/datasets/preprocessing/
‚îú‚îÄ‚îÄ __init__.py                  # Public API
‚îú‚îÄ‚îÄ pipeline.py                  # UnifiedPreprocessingPipeline (single entry point)
‚îú‚îÄ‚îÄ strategies/                  # Strategy pattern for different approaches
‚îÇ   ‚îú‚îÄ‚îÄ document_detection.py   # All detection strategies (Harris, Shi-Tomasi, doctr, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ corner_refinement.py    # Corner selection algorithms
‚îÇ   ‚îú‚îÄ‚îÄ perspective_correction.py # Warping and geometric transforms
‚îÇ   ‚îî‚îÄ‚îÄ enhancement.py           # Brightness, CLAHE, noise elimination
‚îú‚îÄ‚îÄ validation.py                # Consolidated validation (merge 3 files)
‚îú‚îÄ‚îÄ geometry.py                  # Geometric utilities (RANSAC, fitting, etc.)
‚îî‚îÄ‚îÄ presets.py                   # Named presets (office_lens, camscanner, basic, etc.)
```

**Benefits:**
- Reduce 28 files ‚Üí ~10 files
- Single `UnifiedPreprocessingPipeline` with compose-able steps
- Clear strategy selection via config
- Eliminate duplicate validation logic
- 60% reduction in preprocessing LOC through consolidation

**Estimated Effort:** 2-3 days
**Risk:** Medium (comprehensive testing required)

---

### üî¥ CRITICAL #2: Coordinate Transformation Duplication

**Impact:** CRITICAL - BUG-20251116-001 was caused by this issue
**Files Affected:** 5+ files
**Bug Reference:** BUG-20251116-001 ("inference inverse-mapping must match padding position")

#### Problem Description

Coordinate transformation logic (original ‚Üí preprocessed space mapping) is **duplicated across multiple files**:

**Files with coordinate transformation logic:**
1. `ocr/inference/engine.py` - Main inference engine
2. `ocr/inference/postprocess.py` - Postprocessing pipeline
3. `ocr/inference/coordinate_manager.py` - Centralized manager (added to fix duplication)
4. `ocr/evaluation/evaluator.py` - Evaluation pipeline
5. `ocr/lightning_modules/callbacks/wandb_image_logging.py` - WandB logging

#### Why This Is Critical

**Evidence from codebase comments:**
```python
# From coordinate_manager.py (line 3):
"""
Centralized coordinate transformation management.

This module consolidates coordinate transformation logic previously
duplicated across engine.py and postprocess.py to ensure consistency
and prevent bugs like BUG-20251116-001.
"""

# From evaluation/evaluator.py (line 789):
# BUG-20251116-001: Must use coordinate_manager for inverse mapping
```

**Impact:**
- Coordinate misalignment bugs are **CRITICAL** - they cause incorrect polygon outputs
- Bug BUG-20251116-001 affected 26.5% of training data
- Multiple transformation implementations can diverge during maintenance

#### Recommended Solution

**AUDIT and CONSOLIDATE all coordinate transformations:**

1. **Verify all files use `coordinate_manager.py`:**
   ```bash
   # Audit all inverse matrix calculations
   grep -r "inverse.*matrix\|inv_matrix\|transform.*coord" ocr/
   ```

2. **Refactor any remaining duplication:**
   - Move ALL coordinate logic to `coordinate_manager.py`
   - Update `engine.py`, `postprocess.py`, `evaluator.py` to use centralized manager
   - Add validation to ensure consistency

3. **Add regression tests:**
   - Test coordinate round-trip (original ‚Üí transformed ‚Üí inverse ‚Üí original)
   - Test padding compensation
   - Test EXIF orientation handling

**Estimated Effort:** 1 day
**Risk:** High (coordinate bugs are critical, but centralized logic reduces risk)

---

### üî¥ CRITICAL #3: Extreme Nesting Depth in Performance-Critical Code

**Impact:** HIGH - Difficult to maintain, test, and debug
**Files Affected:** Multiple files with 6-9 nesting levels

#### Files with Critical Nesting Depth

| File | Nesting | LOC | Purpose | Impact |
|------|---------|-----|---------|--------|
| `preprocessing/corner_selection.py` | **9 levels** | 324 | Corner detection | HIGH |
| `models/core/registry.py` | 8 levels | 294 | Component registry | MEDIUM |
| `lightning_modules/callbacks/wandb_image_logging.py` | 8 levels | ? | Logging callback | LOW |
| `utils/config.py` | 8 levels | 414 | Config management | MEDIUM |
| `utils/wandb_utils.py` | 8 levels | 663 | WandB utilities | LOW |
| `preprocessing/advanced_detector.py` | 7 levels | 661 | Document detection | HIGH |
| `utils/perspective_correction/fitting.py` | 7 levels | 739 | Geometry fitting | HIGH |

#### Why This Is Critical

**Cognitive Load:** Code with 9 nesting levels is extremely difficult to reason about
**Testing:** Deep nesting makes unit testing nearly impossible without extensive mocking
**Bugs:** Complex conditional paths hide edge cases

**Example from `corner_selection.py`:**
```python
def detect_corners(...):
    if condition1:
        if condition2:
            for item in items:
                if condition3:
                    try:
                        if condition4:
                            for x in range(...):
                                if condition5:
                                    if condition6:
                                        # 9 levels deep!
```

#### Recommended Solution

**Extract nested logic into helper functions:**

```python
# BEFORE (9 levels):
def detect_corners(...):
    if condition1:
        if condition2:
            for item in items:
                if condition3:
                    # ... 6 more levels

# AFTER (3 levels max):
def detect_corners(...):
    if not condition1 or not condition2:
        return early_exit()

    return process_items(items)  # Extract to helper

def process_items(items):
    # Extracted logic with reduced nesting
    filtered = [item for item in items if condition3]
    return [process_single_item(item) for item in filtered]

def process_single_item(item):
    # Further extracted logic
    ...
```

**Target Files (Priority Order):**
1. `preprocessing/corner_selection.py` (9 levels ‚Üí max 4)
2. `models/core/registry.py` (8 levels ‚Üí max 4)
3. `utils/config.py` (8 levels ‚Üí max 4)
4. `preprocessing/advanced_detector.py` (7 levels ‚Üí max 4)
5. `utils/perspective_correction/fitting.py` (7 levels ‚Üí max 4)

**Estimated Effort:** 1-2 days
**Risk:** Low (extract method refactoring is safe with tests)

---

## High Priority Issues (Priority 2)

### üü° HIGH #4: Data Validation Scattered Across Multiple Modules

**Impact:** MEDIUM - Confusion about validation contracts, duplicate logic
**Files Affected:** 3 files, ~1,670 LOC

#### Problem Description

Data validation logic exists in **three separate locations**:

1. **`ocr/validation/models.py`** (593 LOC)
   - 38 Pydantic validation models
   - Runtime validation contracts

2. **`ocr/datasets/schemas.py`** (498 LOC)
   - Dataset-specific validation
   - Polygon validation
   - BUG-20251110-001 validation (26.5% data corruption fix)

3. **`ocr/datasets/preprocessing/validators.py`** (381 LOC)
   - Preprocessing input validation
   - Geometric validation

4. **`ocr/datasets/preprocessing/contracts.py`** (also exists)
   - Additional preprocessing contracts

**Why This Is An Issue:**
- Unclear which validation layer handles which checks
- Polygon validation happens in **both** `schemas.py` AND `preprocessing/validators.py`
- Difficult to understand complete validation rules

#### Recommended Solution

**CONSOLIDATE validation into single module:**

```python
# Proposed structure:
ocr/validation/
‚îú‚îÄ‚îÄ __init__.py          # Public API
‚îú‚îÄ‚îÄ contracts.py         # All Pydantic models (merge models.py + schemas.py)
‚îú‚îÄ‚îÄ polygon.py           # Polygon-specific validation (extracted)
‚îú‚îÄ‚îÄ preprocessing.py     # Preprocessing validation (from validators.py)
‚îî‚îÄ‚îÄ runtime_checks.py    # Runtime assertions and checks
```

**Benefits:**
- Single source of truth for data contracts
- Clear separation: static (Pydantic) vs runtime validation
- Easier to audit validation rules
- Reduce duplicate polygon validation

**Estimated Effort:** 1 day
**Risk:** Low (validation logic is self-contained)

---

### üü° HIGH #5: Dataset Base Class Is Too Large

**Impact:** MEDIUM - Single file with too many responsibilities
**File:** `ocr/datasets/base.py` (896 LOC, 23 methods)

#### Problem Description

The `ValidatedOCRDataset` class handles:
- Image loading and EXIF normalization
- Annotation parsing and validation
- Polygon filtering and validation
- Image preloading and caching
- Map preloading (probability/threshold maps)
- Transform application
- Data augmentation coordination

**This violates Single Responsibility Principle.**

#### Recommended Solution

**EXTRACT responsibilities into separate classes:**

```python
# Proposed structure:
ocr/datasets/
‚îú‚îÄ‚îÄ base.py (200 LOC)              # Slim dataset coordinator
‚îú‚îÄ‚îÄ loaders/
‚îÇ   ‚îú‚îÄ‚îÄ image_loader.py            # Image loading + EXIF (extract from base.py)
‚îÇ   ‚îú‚îÄ‚îÄ annotation_loader.py       # Annotation parsing
‚îÇ   ‚îî‚îÄ‚îÄ map_loader.py              # Map preloading
‚îú‚îÄ‚îÄ caching/
‚îÇ   ‚îú‚îÄ‚îÄ image_cache.py             # Image preloading cache
‚îÇ   ‚îî‚îÄ‚îÄ map_cache.py               # Map cache
‚îú‚îÄ‚îÄ validation/
‚îÇ   ‚îî‚îÄ‚îÄ polygon_validator.py       # Polygon filtering (or merge with ocr/validation/)
‚îî‚îÄ‚îÄ preprocessing/                 # (already exists)
```

**Benefits:**
- Reduce base.py from 896 LOC ‚Üí ~200 LOC
- Each loader is independently testable
- Clearer separation of concerns
- Easier to optimize individual components

**Estimated Effort:** 1-2 days
**Risk:** Medium (core dataset class, needs careful testing)

---

## Medium Priority Issues (Priority 3)

### üü¢ MEDIUM #6: Configuration Management Fragmentation

**Files:**
- `ocr/utils/config.py` (414 LOC, 8 nesting levels)
- `ocr/utils/config_utils.py` (exists)
- `ocr/utils/config_loader.py` (may exist)

**Issue:** Multiple config-related files with unclear responsibilities

**Recommendation:** Consolidate into single `ConfigManager` with clear API

**Estimated Effort:** 1 day
**Risk:** Low

---

### üü¢ MEDIUM #7: Model Architecture Initialization Complexity

**File:** `ocr/models/architecture.py` (157 LOC, 6 nesting levels)

**Issue:**
- Multiple initialization pathways (registry-based, component-based, overrides)
- Backward compatibility handling for `architectures` ‚Üí `architecture_name` migration
- Complex fallback logic

**Recommendation:**
- Simplify initialization logic
- Remove deprecated migration paths (if migration is complete)
- Extract component override logic into separate module

**Estimated Effort:** 1 day
**Risk:** Medium (architecture initialization is critical)

---

### üü¢ MEDIUM #8: WandB Logging Utilities Too Large

**File:** `ocr/utils/wandb_utils.py` (663 LOC, 21+ functions, 8 nesting levels)

**Issue:** Single file with extensive WandB logging logic

**Recommendation:**
- Split into multiple modules by functionality:
  - `wandb_logger.py` - Core logging
  - `wandb_images.py` - Image logging utilities
  - `wandb_metrics.py` - Metrics tracking
  - `wandb_artifacts.py` - Artifact management

**Estimated Effort:** 1 day
**Risk:** Low

---

## Documented Technical Debt

### BUG Markers in Codebase

Multiple BUG markers document known issues and fixes:

| Bug ID | Description | Status | Files Affected | Impact |
|--------|-------------|--------|----------------|--------|
| **BUG-20251110-001** | 26.5% data corruption from invalid coordinates | FIXED | `datasets/base.py`, `datasets/schemas.py` | HIGH |
| **BUG-20251116-001** | Inverse matrix must match padding position | FIXED | `inference/coordinate_manager.py` (3 refs), `evaluation/evaluator.py`, `lightning_modules/callbacks/wandb_image_logging.py` | CRITICAL |
| **BUG-20251112-001/013** | Tensor validation to prevent regressions | FIXED | `models/loss/bce_loss.py`, `models/loss/dice_loss.py`, `lightning_modules/ocr_pl.py` | MEDIUM |

**Recommendation:** Keep BUG markers for historical reference and regression testing

---

## Architecture Strengths (Preserve These)

### ‚úÖ Component Registry Pattern

**Location:** `ocr/models/core/registry.py`

**Why It's Good:**
- Enables plug-and-play experimentation with encoders, decoders, heads, losses
- Clean separation of model components
- Easy to add new architectures

**Recommendation:** PRESERVE - This is excellent design

---

### ‚úÖ Pipeline Orchestration Pattern

**Locations:**
- `ocr/datasets/preprocessing/pipeline.py`
- `ocr/inference/postprocess.py`
- `ocr/inference/orchestrator.py`

**Why It's Good:**
- Clear responsibility boundaries
- Well-structured data flow
- Testable components

**Recommendation:** PRESERVE - Use as template for other refactorings

---

### ‚úÖ Pydantic Data Validation

**Location:** Throughout codebase

**Why It's Good:**
- Type-safe data contracts
- Early error detection at boundaries
- Self-documenting data structures

**Recommendation:** PRESERVE and CONSOLIDATE (see Issue #4)

---

## High-Risk Areas Requiring Careful Testing

### üö® Risk Level: CRITICAL

1. **Coordinate Transformation System**
   - Files: `coordinate_manager.py`, `engine.py`, `postprocess.py`, `evaluator.py`
   - Risk: Coordinate bugs cause incorrect outputs
   - Testing Required: Extensive integration tests with various image sizes, padding, EXIF orientations

2. **Dataset Loading Pipeline**
   - File: `datasets/base.py`
   - Risk: Data loading bugs affect training quality
   - Testing Required: Test with corrupt images, invalid polygons, edge cases

3. **Model Architecture Initialization**
   - File: `models/architecture.py`
   - Risk: Initialization bugs break training
   - Testing Required: Test all architecture presets, component overrides

### üö® Risk Level: HIGH

4. **Preprocessing Pipeline**
   - Files: 28 files in `preprocessing/`
   - Risk: Preprocessing bugs affect model performance
   - Testing Required: Visual inspection of preprocessing outputs, regression tests

5. **Loss Functions**
   - Files: `models/loss/*.py`
   - Risk: Loss calculation bugs cause training instability (BUG-20251112-001/013)
   - Testing Required: Tensor shape validation, gradient flow tests

---

## Refactoring Priority Matrix

| Issue | Priority | Impact | Effort | Risk | Recommended Order |
|-------|----------|--------|--------|------|-------------------|
| #2 Coordinate Duplication | CRITICAL | CRITICAL | 1 day | High | **1st** (prevents critical bugs) |
| #3 Extreme Nesting | CRITICAL | HIGH | 1-2 days | Low | **2nd** (improves maintainability) |
| #1 Preprocessing Fragmentation | CRITICAL | HIGH | 2-3 days | Medium | **3rd** (largest consolidation) |
| #4 Validation Scattered | HIGH | MEDIUM | 1 day | Low | **4th** (cleanup) |
| #5 Dataset Base Too Large | HIGH | MEDIUM | 1-2 days | Medium | **5th** (improves testability) |
| #6 Config Fragmentation | MEDIUM | MEDIUM | 1 day | Low | 6th |
| #7 Architecture Init | MEDIUM | MEDIUM | 1 day | Medium | 7th |
| #8 WandB Utils Large | MEDIUM | LOW | 1 day | Low | 8th |

---

## Proposed Refactoring Roadmap

### Phase 1: Critical Bug Prevention (Week 1)
**Goal:** Eliminate high-risk areas that can cause critical bugs

1. **Day 1:** Audit and consolidate coordinate transformation logic (#2)
   - Verify all files use `coordinate_manager.py`
   - Add regression tests for BUG-20251116-001
   - Document coordinate transformation flow

2. **Days 2-3:** Reduce nesting depth in critical files (#3)
   - `corner_selection.py` (9 ‚Üí 4 levels)
   - `advanced_detector.py` (7 ‚Üí 4 levels)
   - `fitting.py` (7 ‚Üí 4 levels)

### Phase 2: Major Consolidation (Week 2-3)
**Goal:** Reduce code fragmentation and improve organization

3. **Days 4-6:** Consolidate preprocessing pipeline (#1)
   - Create unified pipeline architecture
   - Migrate 28 files ‚Üí 10 files
   - Implement strategy pattern for detection algorithms
   - Add comprehensive tests

4. **Day 7:** Consolidate validation modules (#4)
   - Merge `validation/models.py` + `datasets/schemas.py`
   - Extract polygon validation
   - Update imports across codebase

### Phase 3: Code Quality Improvements (Week 3-4)
**Goal:** Improve maintainability and testability

5. **Days 8-9:** Extract dataset responsibilities (#5)
   - Create separate loader modules
   - Extract caching logic
   - Slim down base.py to coordinator role

6. **Days 10-12:** Clean up configuration and utilities (#6, #7, #8)
   - Consolidate config management
   - Simplify architecture initialization
   - Split WandB utilities

---

## Testing Strategy

### Required Test Coverage

For each refactoring, ensure:

1. **Unit Tests:**
   - Test individual functions in isolation
   - Mock external dependencies
   - Cover edge cases

2. **Integration Tests:**
   - Test component interactions
   - Test data flow through pipelines
   - Test coordinate transformations end-to-end

3. **Regression Tests:**
   - Test all documented BUG fixes
   - Test critical paths (training, inference, evaluation)
   - Visual inspection of preprocessing outputs

4. **Performance Tests:**
   - Ensure refactoring doesn't degrade performance
   - Benchmark preprocessing pipeline
   - Profile memory usage

---

## Success Metrics

Track these metrics to measure refactoring success:

| Metric | Current | Target | Method |
|--------|---------|--------|--------|
| Preprocessing Files | 28 files | 10 files | File count |
| Preprocessing LOC | 8,273 LOC | ~3,500 LOC | Line count |
| Max Nesting Depth | 9 levels | 4 levels | Code analysis |
| Validation Modules | 3 modules | 1 module | File count |
| Dataset base.py Size | 896 LOC | 200 LOC | Line count |
| Coordinate Duplication | 5 files | 1 file | Code audit |
| Test Coverage | Unknown | 80%+ | pytest coverage |

---

## Recommendations Summary

### Immediate Actions (This Week)
1. ‚úÖ **Fix coordinate transformation duplication** (#2) - CRITICAL for preventing bugs
2. ‚úÖ **Reduce nesting depth** in `corner_selection.py`, `advanced_detector.py`, `fitting.py` (#3)

### Short Term (Next 2 Weeks)
3. ‚úÖ **Consolidate preprocessing pipeline** (#1) - Largest impact on maintainability
4. ‚úÖ **Consolidate validation modules** (#4) - Improves clarity

### Medium Term (Next Month)
5. ‚úÖ **Extract dataset responsibilities** (#5) - Improves testability
6. ‚úÖ **Clean up configuration and utilities** (#6, #7, #8)

### Long Term (Next Quarter)
7. üîÑ **Increase test coverage** to 80%+
8. üîÑ **Document architecture** with diagrams
9. üîÑ **Set up automated code quality checks** (max nesting, file size limits)

---

## Conclusion

The OCR codebase is **fundamentally sound** with good architectural patterns (component registry, pipeline orchestration, Pydantic validation). However, it suffers from **code fragmentation** in critical areas:

**Top 3 Issues:**
1. üî¥ Preprocessing pipeline fragmentation (28 files ‚Üí needs consolidation)
2. üî¥ Coordinate transformation duplication (high bug risk)
3. üî¥ Extreme nesting depth (up to 9 levels ‚Üí hard to maintain)

**Recommended Approach:**
- Focus on **Critical Bug Prevention** first (coordinate transforms, nesting reduction)
- Then tackle **Major Consolidation** (preprocessing, validation)
- Finally, improve **Code Quality** (dataset refactoring, config cleanup)

**Expected Outcome:**
- 60% reduction in preprocessing code (8273 ‚Üí ~3500 LOC)
- Elimination of critical bug risk areas
- Improved maintainability and testability
- Clearer code organization

**Overall Assessment:** The refactoring is **feasible and recommended**. The codebase quality is good enough that targeted refactoring will yield significant benefits without requiring a complete rewrite.
