# @package dataloaders

# Optimized dataloader settings for Intel i5 16-core processor
# Tuned for maximum throughput while maintaining CUDA safety

train_dataloader:
  batch_size: ${batch_size}
  shuffle: true
  num_workers: 12  # ~75% of 16 cores, leaving headroom for main process
  pin_memory: true  # CUDA optimization: faster host-to-device transfer
  persistent_workers: true  # Keep workers alive between epochs
  prefetch_factor: 3  # Higher prefetch for faster training

val_dataloader:
  batch_size: ${batch_size}
  shuffle: false
  num_workers: 8  # Fewer workers for validation to balance resources
  pin_memory: true
  persistent_workers: true
  prefetch_factor: 2

test_dataloader:
  batch_size: ${batch_size}
  shuffle: false
  num_workers: 4  # Minimal workers for testing
  pin_memory: true
  persistent_workers: true
  prefetch_factor: 2

predict_dataloader:
  batch_size: ${batch_size}
  shuffle: false
  num_workers: 4  # Minimal workers for inference
  pin_memory: true
  persistent_workers: true
  prefetch_factor: 2
