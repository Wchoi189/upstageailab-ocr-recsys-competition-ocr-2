upstageailab-ocr-recsys-competition-ocr-2 â¯ uv run python runners/train.py \
    domain=recognition \
    trainer=hardware_rtx3090_24gb_i5_16core \
    exp_name="repro_segfault_short_v1" \
    ++dataloaders.train_dataloader.num_workers=4 \
    ++dataloaders.val_dataloader.num_workers=4 \
    ++trainer.limit_train_batches=125 \
    ++trainer.limit_val_batches=40 \
    ++trainer.max_epochs=1 \
    ++skip_test=True \
    ++training.logger.wandb.project="ocr-recognition-debug" \
    ++training.logger.wandb.job_type="debug_fix"
INFO: Seed set to 42
[2026-01-16 00:12:10,064][lightning.fabric.utilities.seed][INFO] - Seed set to 42
INFO     ocr.features.recognition.data.tokenizer - Loaded tokenizer: 1023 chars,
         vocab_size=1027, max_len=25
[2026-01-16 00:12:10,166][ocr.features.recognition.data.tokenizer][INFO] - Loaded tokenizer: 1023 chars, vocab_size=1027, max_len=25
[2026-01-16 00:12:10,388][timm.models._builder][INFO] - Loading pretrained weights from Hugging Face hub (timm/vit_small_patch16_224.augreg_in21k_ft_in1k)
[2026-01-16 00:12:10,797][timm.models._hub][INFO] - [timm/vit_small_patch16_224.augreg_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
INFO     ocr.features.recognition.data.tokenizer - Loaded tokenizer: 1023 chars,
         vocab_size=1027, max_len=25
[2026-01-16 00:12:10,940][ocr.features.recognition.data.tokenizer][INFO] - Loaded tokenizer: 1023 chars, vocab_size=1027, max_len=25
INFO     ocr.features.recognition.data.lmdb_dataset - LMDBRecognitionDataset: 616366 samples
         from
         /workspaces/upstageailab-ocr-recsys-competition-ocr-2/data/processed/recognition/aihu
         b_lmdb_validation
[2026-01-16 00:12:10,946][ocr.features.recognition.data.lmdb_dataset][INFO] - LMDBRecognitionDataset: 616366 samples from /workspaces/upstageailab-ocr-recsys-competition-ocr-2/data/processed/recognition/aihub_lmdb_validation
INFO     ocr.features.recognition.data.tokenizer - Loaded tokenizer: 1023 chars,
         vocab_size=1027, max_len=25
[2026-01-16 00:12:10,954][ocr.features.recognition.data.tokenizer][INFO] - Loaded tokenizer: 1023 chars, vocab_size=1027, max_len=25
INFO     ocr.features.recognition.data.lmdb_dataset - LMDBRecognitionDataset: 616366 samples
         from
         /workspaces/upstageailab-ocr-recsys-competition-ocr-2/data/processed/recognition/aihu
         b_lmdb_validation
[2026-01-16 00:12:10,960][ocr.features.recognition.data.lmdb_dataset][INFO] - LMDBRecognitionDataset: 616366 samples from /workspaces/upstageailab-ocr-recsys-competition-ocr-2/data/processed/recognition/aihub_lmdb_validation
INFO     ocr.features.recognition.data.tokenizer - Loaded tokenizer: 1023 chars,
         vocab_size=1027, max_len=25
[2026-01-16 00:12:10,967][ocr.features.recognition.data.tokenizer][INFO] - Loaded tokenizer: 1023 chars, vocab_size=1027, max_len=25
INFO     ocr.features.recognition.data.lmdb_dataset - LMDBRecognitionDataset: 616366 samples
         from
         /workspaces/upstageailab-ocr-recsys-competition-ocr-2/data/processed/recognition/aihu
         b_lmdb_validation
[2026-01-16 00:12:10,973][ocr.features.recognition.data.lmdb_dataset][INFO] - LMDBRecognitionDataset: 616366 samples from /workspaces/upstageailab-ocr-recsys-competition-ocr-2/data/processed/recognition/aihub_lmdb_validation
INFO     ocr.features.recognition.data.tokenizer - Loaded tokenizer: 1023 chars,
         vocab_size=1027, max_len=25
[2026-01-16 00:12:10,980][ocr.features.recognition.data.tokenizer][INFO] - Loaded tokenizer: 1023 chars, vocab_size=1027, max_len=25
INFO     ocr.features.recognition.data.lmdb_dataset - LMDBRecognitionDataset: 616366 samples
         from
         /workspaces/upstageailab-ocr-recsys-competition-ocr-2/data/processed/recognition/aihu
         b_lmdb_validation
[2026-01-16 00:12:10,987][ocr.features.recognition.data.lmdb_dataset][INFO] - LMDBRecognitionDataset: 616366 samples from /workspaces/upstageailab-ocr-recsys-competition-ocr-2/data/processed/recognition/aihub_lmdb_validation
INFO: GPU available: True (cuda), used: True
[2026-01-16 00:12:11,503][lightning.pytorch.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
INFO: TPU available: False, using: 0 TPU cores
[2026-01-16 00:12:11,504][lightning.pytorch.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
wandb: Currently logged in as: wchoi189 (ocr-team2) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.23.0
wandb: Run data is saved locally in ./wandb/run-20260116_001213-8fmwx2xr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run user_parseq-timm-backbone-parseq-decoder-parseq-head-cross-entropy-bs16-lr1e-3_SCORE_PLACEHOLDER
wandb: â­ï¸ View project at https://wandb.ai/ocr-team2/receipt-text-recognition-ocr-project
wandb: ğŸš€ View run at https://wandb.ai/ocr-team2/receipt-text-recognition-ocr-project/runs/8fmwx2xr
INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[2026-01-16 00:12:17,505][lightning.pytorch.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ   â”ƒ Name   â”ƒ Type         â”ƒ Params â”ƒ Mode  â”ƒ
â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ 0 â”‚ model  â”‚ PARSeq       â”‚ 51.3 M â”‚ train â”‚
â”‚ 1 â”‚ metric â”‚ CLEvalMetric â”‚      0 â”‚ train â”‚
â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 51.3 M
Non-trainable params: 0
Total params: 51.3 M
Total estimated model params size (MB): 205
Modules in train mode: 443
Modules in eval mode: 0
Sanity Checking â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2/2 0:00:00 â€¢ 0:00:00 0.00it/s  [2026-01-16 00:12:19,050][root][WARNING] - No val predictions found. This may indicate a data loading or prediction issue.
Epoch 0/0  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 125/125 0:00:09 â€¢ 0:00:00 14.35it/s v_num: x2xr[2026-01-16 00:12:29,464][root][WARNING] - No val predictions found. This may indicate a data loading or prediction issue.
INFO: `Trainer.fit` stopped: `max_epochs=1` reached.
[2026-01-16 00:12:41,324][lightning.pytorch.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=1` reached.
Successfully tagged W&B run as completed.
Created success sentinel file at:
/workspaces/upstageailab-ocr-recsys-competition-ocr-2/outputs/experiments/train/ocr/repro_segf
ault_short_v1/20260116_001057_42/checkpoints/.SUCCESS
Epoch 0/0  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 125/125 0:00:09 â€¢ 0:00:00 14.35it/s v_num: x2xr val/recall:
                                                                      0.000 val/precision:
                                                                      0.000 val/hmean: 0.000
Finalized run name: user_parseq-timm-backbone-parseq-decoder-parseq-head-cross-entropy-bs16-lr1e-3_hmean0.000
wandb:
wandb: Run history:
wandb:               epoch â–â–â–
wandb:             lr-Adam â–â–
wandb:          train/loss â–â–ˆ
wandb:       train/loss_ce â–â–ˆ
wandb: trainer/global_step â–â–â–†â–†â–ˆâ–ˆâ–ˆ
wandb:           val/hmean â–
wandb:       val/precision â–
wandb:          val/recall â–
wandb:            val_loss â–
wandb:         val_loss_ce â–
wandb:
wandb: Run summary:
wandb:      checkpoint_dir /workspaces/upstagea...
wandb:               epoch 0
wandb:     final_mean_loss 4.22647
wandb:      final_run_name user_parseq-timm-bac...
wandb:        final_status success
wandb:             lr-Adam 0.001
wandb:          train/loss 4.22647
wandb:       train/loss_ce 4.22647
wandb: trainer/global_step 124
wandb:           val/hmean 0
wandb:                  +4 ...
wandb:
wandb: ğŸš€ View run user_parseq-timm-backbone-parseq-decoder-parseq-head-cross-entropy-bs16-lr1e-3_hmean0.000 at: https://wandb.ai/ocr-team2/receipt-text-recognition-ocr-project/runs/8fmwx2xr
wandb: â­ï¸ View project at: https://wandb.ai/ocr-team2/receipt-text-recognition-ocr-project
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260116_001213-8fmwx2xr/logs
*upstageailab-ocr-recsys-competition-ocr-2 â¯
