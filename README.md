<div align="center">

[![CI](https://github.com/Wchoi189/upstageailab-ocr-recsys-competition-ocr-2/actions/workflows/ci.yml/badge.svg)](https://github.com/Wchoi189/upstageailab-ocr-recsys-competition-ocr-2/actions)
[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.8+-red.svg)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

# OCR Text Detection & Recognition System

**Modular, production-ready OCR for receipt text detection and recognition**

[Quick Start](#-quick-start) â€¢ [Features](#-features) â€¢ [Documentation](#-documentation) â€¢ [Progress](#-project-progress)

</div>

---

## ğŸ“– About

A comprehensive OCR system for detecting and recognizing text in receipt images. Built with PyTorch Lightning and Hydra for modularity and production readiness.

**Key Features:**
- ğŸ¯ DBNet-based text detection with 97.8% H-Mean
- âš¡ 5-8x faster training with offline preprocessing
- ğŸ§© Modular architecture (plug-and-play components)
- ğŸ¨ Interactive UI tools (Streamlit + React + Next.js)
- ğŸ“Š W&B integration for experiment tracking

---

## ğŸš€ Quick Start

```bash
# Clone and setup
git clone <your-repo-url>
cd upstageailab-ocr-recsys-competition-ocr-2
./scripts/setup/00_setup-environment.sh

# Train a model
uv run python runners/train.py model/presets=model_example trainer.max_epochs=10

# Run inference UI
python run_ui.py inference
```

**Prerequisites:** Python 3.11+, UV package manager, CUDA GPU (recommended)

ğŸ“˜ **Detailed guides:** [Installation](docs/guides/installation.md) â€¢ [Training](docs/guides/training.md) â€¢ [Configuration](docs/architecture/CONFIG_ARCHITECTURE.md)

---

## âœ¨ Features

<div align="center">

| **Command Builder** | **Real-time Inference** | **Evaluation Viewer** |
|:---:|:---:|:---:|
| ![Command Builder](docs/assets/images/demo/command-builder-predict-command-generate.png) | ![Inference](docs/assets/images/demo/real-time-ocr-inference-select-img.png.jpg) | ![Evaluation](docs/assets/images/demo/ocr-eval-results-viewer-gallery.png) |
| Build training commands | Test models interactively | Analyze results visually |

</div>

### Current Capabilities

âœ… **Text Detection** - DBNet architecture with polygon outputs
âœ… **Offline Preprocessing** - Pre-computed maps for 5-8x speedup
âœ… **Modular Components** - Registry-based encoders, decoders, heads, losses
âœ… **Modular Inference Engine** - 8-component orchestrator pattern with 67% code reduction
âœ… **Modern UIs** - Streamlit tools + React SPA + Next.js console
âœ… **FastAPI Backend** - Inference API with job tracking

### Planned Features

ğŸ”œ **Text Recognition** - End-to-end OCR pipeline
ğŸ”œ **Layout Analysis** - Document structure understanding
ğŸ”œ **Multi-language Support** - Beyond English receipts

---

## ğŸ“Š Project Progress

<div align="center">

| Phase | Status | Progress |
|-------|--------|----------|
| **Phase 1-3: Core Features** | âœ… Complete | 100% |
| **Phase 4: Testing & QA** | ğŸŸ¡ In Progress | 40% |
| **Phase 5: Next.js Migration** | ğŸŸ¡ In Progress | 75% |
| **Phase 6-7: Future Work** | âšª Planned | 0% |

**Overall: 55% Complete**

</div>

### Recent Highlights

- âœ… Config architecture consolidation (43% cognitive load reduction)
- âœ… Client-side background removal with ONNX.js
- âœ… FastAPI backend with real inference API
- âœ… Next.js console with Chakra UI

**Current Focus:** E2E testing, Next.js API routes, analytics integration

ğŸ“‹ **Detailed roadmap:** [docs/roadmap.md](docs/roadmap.md)

---

## ğŸ› ï¸ Tech Stack

| Category | Technologies |
|----------|-------------|
| **ML/DL** | PyTorch, PyTorch Lightning, Hydra |
| **Backend** | FastAPI, ONNX Runtime |
| **Frontend** | React 19, Next.js 16, Chakra UI, Streamlit |
| **Tools** | UV (Python), npm, W&B, Playwright, Vitest |

---

## ğŸ“š Documentation

**Getting Started**
- [Installation Guide](docs/guides/installation.md)
- [Training Guide](docs/guides/training.md)
- [Configuration Guide](docs/architecture/CONFIG_ARCHITECTURE.md)

**Development**
- [Architecture Overview](docs/architecture/architecture.md)
- [Contributing Guidelines](CONTRIBUTING.md)
- [AgentQMS Workflows](AgentQMS/knowledge/agent/system.md)

**Reference**
- [API Documentation](docs/api-reference.md)
- [Changelog](CHANGELOG.md)
- [Troubleshooting](docs/guides/troubleshooting.md)

---

## ğŸ—ï¸ Project Structure

```
â”œâ”€â”€ apps/              # Frontend & backend applications
â”œâ”€â”€ configs/           # Hydra configuration (89 YAML files)
â”œâ”€â”€ docs/              # Documentation & artifacts
â”œâ”€â”€ ocr/               # Core OCR Python package
â”œâ”€â”€ runners/           # Training/testing/prediction scripts
â”œâ”€â”€ scripts/           # Utility scripts
â”œâ”€â”€ tests/             # Unit & integration tests
â””â”€â”€ ui/                # Streamlit UI applications
```

ğŸ“– **Detailed structure:** [docs/architecture/project-structure.md](docs/architecture/project-structure.md)

---

## ğŸ¤ Contributing

Contributions welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

**Quick checklist:**
- Fork & create feature branch
- Add tests for new features
- Update documentation
- Submit pull request

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- [DBNet](https://github.com/MhLiao/DB) - Text detection architecture
- [CLEval](https://github.com/clovaai/CLEval) - Evaluation metrics
- [PyTorch Lightning](https://lightning.ai) - Training framework
- [Hydra](https://hydra.cc) - Configuration management

---

<div align="center">

**Built with â¤ï¸ for OCR research and development**

[â¬† Back to Top](#ocr-text-detection--recognition-system)

</div>
