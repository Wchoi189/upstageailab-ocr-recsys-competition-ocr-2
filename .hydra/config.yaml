seed: 42
exp_name: ocr_training_b
resume: null
project_name: null
experiment_tag: null
wandb: true
compile_model: false
model:
  name: parseq
  architecture_name: parseq
  architectures: parseq
  component_overrides:
    encoder:
      name: timm_backbone
      params:
        model_name: vit_small_patch16_224
        pretrained: true
        dynamic_img_size: true
        output_indices:
        - -1
    decoder:
      name: parseq_decoder
      params:
        d_model: 384
        nhead: 12
        num_layers: 12
        dim_feedforward: 1536
        dropout: 0.1
        max_len: 26
    head:
      name: parseq_head
      params:
        in_channels: 384
    loss:
      name: cross_entropy
      params:
        ignore_index: 0
  optimizer:
    _target_: torch.optim.Adam
    lr: 0.001
    betas:
    - 0.9
    - 0.999
    eps: 1.0e-08
    weight_decay: 0.0001
  _target_: ocr.core.models.architecture.OCRModel
  scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    T_max: 1000
    eta_min: 0
  type: recognition
  task_type: recognition
data:
  _target_: torchvision.transforms.Compose
  transforms:
  - _target_: torchvision.transforms.Resize
    size:
    - 32
    - 128
  - _target_: torchvision.transforms.ToTensor
  - _target_: torchvision.transforms.Normalize
    mean:
    - 0.485
    - 0.456
    - 0.406
    std:
    - 0.229
    - 0.224
    - 0.225
  tokenizer:
    _target_: ocr.features.recognition.data.tokenizer.KoreanOCRTokenizer
    charset_path: ${paths.data_root}/ocr/data/charset.json
    max_len: 25
  _dataset_template:
    _target_: ocr.features.recognition.data.lmdb_dataset.LMDBRecognitionDataset
    lmdb_path: ${paths.data_root}/data/processed/recognition/aihub_lmdb_validation
    tokenizer: ${tokenizer}
    max_len: ${data.tokenizer.max_len}
  train_dataset:
    _target_: ocr.features.recognition.data.lmdb_dataset.LMDBRecognitionDataset
    lmdb_path: ${paths.data_root}/data/processed/recognition/aihub_lmdb_validation
    tokenizer: ${tokenizer}
    max_len: ${data.tokenizer.max_len}
  val_dataset:
    _target_: ocr.features.recognition.data.lmdb_dataset.LMDBRecognitionDataset
    lmdb_path: ${paths.data_root}/data/processed/recognition/aihub_lmdb_validation
    tokenizer: ${tokenizer}
    max_len: ${data.tokenizer.max_len}
  test_dataset:
    _target_: ocr.features.recognition.data.lmdb_dataset.LMDBRecognitionDataset
    lmdb_path: ${paths.data_root}/data/processed/recognition/aihub_lmdb_validation
    tokenizer: ${tokenizer}
    max_len: ${data.tokenizer.max_len}
  predict_dataset:
    _target_: ocr.features.recognition.data.lmdb_dataset.LMDBRecognitionDataset
    lmdb_path: ${paths.data_root}/data/processed/recognition/aihub_lmdb_validation
    tokenizer: ${tokenizer}
    max_len: ${data.tokenizer.max_len}
  collate_fn:
    _target_: ocr.data.datasets.recognition_collate_fn.recognition_collate_fn
  dataloaders:
    train_dataloader:
      batch_size: ${batch_size}
      shuffle: true
      num_workers: 4
      pin_memory: true
      persistent_workers: true
      prefetch_factor: 3
    val_dataloader:
      batch_size: ${batch_size}
      shuffle: false
      num_workers: 4
      pin_memory: true
      persistent_workers: true
      prefetch_factor: 2
    test_dataloader:
      batch_size: ${batch_size}
      shuffle: false
      num_workers: 4
      pin_memory: true
      persistent_workers: true
      prefetch_factor: 2
    predict_dataloader:
      batch_size: ${batch_size}
      shuffle: false
      num_workers: 4
      pin_memory: true
      persistent_workers: true
      prefetch_factor: 2
  task_type: recognition
metrics:
  eval:
    _target_: ocr.core.metrics.cleval_metric.CLEvalMetric
    dist_sync_on_step: false
    case_sensitive: true
    recall_gran_penalty: 1.0
    precision_gran_penalty: 1.0
    vertical_aspect_ratio_thresh: 0.5
    ap_constraint: 0.3
    scale_wise: false
    scale_bins:
    - 0.0
    - 0.005
    - 0.01
    - 0.015
    - 0.02
    - 0.025
    - 0.1
    - 0.5
    - 1.0
    scale_range:
    - 0.0
    - 1.0
    max_polygons: 500
paths:
  outputs_root: ${hydra:runtime.cwd}/outputs
  experiments_root: ${paths.outputs_root}/experiments
  artifacts_root: ${paths.outputs_root}/artifacts
  logs_root: ${paths.outputs_root}/logs
  wandb_sync_root: ${paths.outputs_root}/wandb_sync
  output_dir: ${hydra:runtime.output_dir}
  log_dir: ${paths.output_dir}/logs
  checkpoint_dir: ${paths.output_dir}/checkpoints
  submission_dir: ${paths.output_dir}/submissions
  data_root: ${hydra:runtime.cwd}
logger:
  wandb:
    enabled: true
    log_model: all
    project_name: receipt-text-recognition-ocr-project
    exp_version: v1.0
    settings:
      offline: false
      save_code: false
      sync_dir: ${paths.wandb_sync_root}
    per_batch_image_logging:
      enabled: false
      recall_threshold: 0.4
      max_batches_per_epoch: 2
      max_images_per_batch: 4
      use_transformed_batch: true
      image_format: jpeg
      max_image_side: 640
  csv:
    _target_: lightning.pytorch.loggers.csv_logs.CSVLogger
    save_dir: ${paths.output_dir}
    name: csv/
    prefix: ''
batch_size: 8
datasets:
  train:
    config:
      preload_images: true
      load_maps: true
      cache_config:
        cache_transformed_tensors: false
        cache_images: true
        cache_maps: true
        log_statistics_every_n: 100
  val_dataset:
    config:
      preload_images: true
      load_maps: true
trainer:
  limit_train_batches: 20
  limit_val_batches: 5
  max_epochs: 2
training:
  callbacks:
    model_checkpoint:
      _target_: ocr.core.lightning.callbacks.unique_checkpoint.UniqueModelCheckpoint
      dirpath: ${paths.checkpoint_dir}
      experiment_tag: ${oc.env:EXPERIMENT_TAG,${exp_name}}
      training_phase: training
      add_timestamp: true
      filename: best
      monitor: val/hmean
      verbose: false
      save_last: true
      save_top_k: 1
      mode: max
      auto_insert_metric_name: true
      save_weights_only: false
      every_n_train_steps: null
      train_time_interval: null
      every_n_epochs: 1
      save_on_train_epoch_end: false
    early_stopping:
      _target_: lightning.pytorch.callbacks.EarlyStopping
      monitor: val/hmean
      min_delta: 0.0
      patience: 5
      verbose: false
      mode: max
      strict: true
      check_finite: true
      stopping_threshold: null
      divergence_threshold: null
      check_on_train_epoch_end: false
    rich_progress_bar:
      _target_: lightning.pytorch.callbacks.RichProgressBar
      theme:
        _target_: lightning.pytorch.callbacks.progress.rich_progress.RichProgressBarTheme
        progress_bar: red
        progress_bar_finished: green
        progress_bar_pulse: yellow
        time: cyan
        processing_speed: cyan
        description: bold white
        metrics: white
      refresh_rate: 2
    performance_profiler:
      _target_: ocr.core.lightning.callbacks.PerformanceProfilerCallback
      enabled: false
      log_interval: 10
      profile_memory: true
      verbose: false
    metadata:
      _target_: ocr.core.lightning.callbacks.MetadataCallback
      exp_name: ${exp_name}
      outputs_dir: ${paths.output_dir}
      training_phase: training
    wandb_completion:
      _target_: ocr.core.lightning.callbacks.wandb_completion.WandbCompletionCallback
callbacks:
  wandb_image_logging:
    _target_: ocr.core.lightning.callbacks.wandb_image_logging.WandbImageLoggingCallback
    log_every_n_epochs: 1
debug:
  verbose: false
  profiling: false
task_name: train
experiment:
  kind: train
  task: ocr
  name: ${exp_name}
  run_id: ${now:%Y%m%d_%H%M%S}_${seed}
ignore_warnings: false
enforce_tags: true
print_config: true
dataset_module: ocr.data.datasets
dataset_config_module: ocr.core.validation
dataset_path: ${dataset_module}
dataset_config_path: ${dataset_config_module}
model_path: ocr.core.models
encoder_path: ocr.core.models.encoder
decoder_path: ocr.core.models.decoder
head_path: ocr.core.models.head
loss_path: ocr.core.models.loss
lightning_path: ocr.core.lightning
task: recognition
tokenizer:
  charset: ${data.tokenizer.charset_path}
  max_len: 25
