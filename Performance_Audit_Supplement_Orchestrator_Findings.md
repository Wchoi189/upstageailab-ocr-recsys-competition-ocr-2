# Performance Audit Supplement: Orchestrator Implementation Findings

**Date**: 2026-01-19
**Context**: Additional bottlenecks discovered during Phase 4 Orchestrator implementation
**Reference**: `Performance_Audit_OCR_Training_Pipeline_Bottlenecks_1.md`

---

## New Critical Findings

### üî¥ CRITICAL: Duplicate Tokenizer Instantiation (Orchestrator-Specific)

**Location**:
- `ocr/pipelines/orchestrator.py:53`
- `ocr/core/lightning/__init__.py:10` (legacy factory)

**Problem**: Recognition domain instantiates tokenizer **3 times**:

```python
# Call #1: Orchestrator vocab injection
tokenizer = hydra.utils.instantiate(self.cfg.data.tokenizer)  # Line 53

# Call #2: Legacy factory (if still called)
tokenizer = hydra.utils.instantiate(config.data.tokenizer)    # __init__.py:10

# Call #3: Dataset may instantiate again
```

**Impact**: 6-15 seconds (tokenizer instantiation is expensive - loads vocab, builds mappings)

**Fix**:
```python
# In orchestrator.py
def _get_cached_tokenizer(self):
    if not hasattr(self.cfg, '_tokenizer_cache'):
        self.cfg._tokenizer_cache = hydra.utils.instantiate(self.cfg.data.tokenizer)
    return self.cfg._tokenizer_cache

def _inject_vocab_size(self):
    tokenizer = self._get_cached_tokenizer()  # Use cached version
    # ... rest of injection logic
```

---

### üî¥ CRITICAL: EagerPyTorch Import in Orchestrator

**Location**: `ocr/pipelines/orchestrator.py:9`

```python
from lightning.pytorch import Trainer  # EAGER IMPORT AT MODULE LOAD
```

**Problem**: When `runners/train.py` imports Orchestrator, it immediately loads:
- Lightning (2-5s)
- PyTorch backend (3-8s)
- All dependencies (CUDA, cuDNN, etc.)

**Impact**: 5-13 seconds before Hydra even starts

**Fix**:
```python
# Remove line 9, add lazy import in setup_trainer()
def setup_trainer(self):
    from lightning.pytorch import Trainer  # LAZY IMPORT
    logger.info("‚ö° Configuring Lightning Trainer...")
    # ... rest of method
```

**Estimated Savings**: 8-12 seconds

---

### üü° HIGH: Hydra Config Struct Mode Overhead

**Location**: `runners/train.py:20-22`

```python
OmegaConf.set_struct(config, False)
if hasattr(config, "hydra") and config.hydra is not None:
    OmegaConf.set_struct(config.hydra, False)
```

**Problem**: This happens AFTER Hydra has already:
1. Loaded all config files
2. Resolved interpolations
3. Validated structure

Disabling struct mode doesn't save time - the resolution already happened.

**Actual Bottleneck**: Hydra's initial composition with V5.0's complex defaults chains:

```yaml
# detection.yaml has 4-level deep defaults
defaults:
  - /global/default          # Level 1
    - /global/paths          # Level 2 (from defaults)
  - /model/architectures/dbnet_atomic  # Complex interpolations
  - /data/datasets/canonical
```

**Impact**: 10-20 seconds in Hydra composition

**Fix**: Consider config caching for development:
```python
import hashlib
import pickle
from pathlib import Path

def get_cached_config(config_name, overrides):
    cache_key = hashlib.md5(f"{config_name}:{overrides}".encode()).hexdigest()
    cache_file = Path(f".hydra_cache/{cache_key}.pkl")

    if cache_file.exists():
        return pickle.load(cache_file.open('rb'))

    # Normal Hydra load...
    cfg = compose(config_name, overrides)
    cache_file.parent.mkdir(exist_ok=True)
    pickle.dump(cfg, cache_file.open('wb'))
    return cfg
```

---

### üü° MEDIUM: Dataset Factory Eager Instantiation

**Location**: `ocr/data/datasets/__init__.py:49-51`

```python
train_dataset = instantiate(datasets_config.train_dataset)  # Line 49
val_dataset = instantiate(datasets_config.val_dataset)      # Line 50
test_dataset = instantiate(datasets_config.test_dataset)    # Line 51
```

**Problem**: All 3 datasets instantiated immediately, even if only train+val are used.

Each instantiation:
1. Scans file system for images
2. Loads annotation JSONs
3. Validates paths
4. Builds internal index

**Impact**: 10-20 seconds (varies by dataset size)

**Fix**: Lazy dataset proxies:
```python
class LazyDataset:
    def __init__(self, config):
        self._config = config
        self._dataset = None

    def __getattr__(self, name):
        if self._dataset is None:
            self._dataset = instantiate(self._config)
        return getattr(self._dataset, name)

def get_datasets_by_cfg(datasets_config, data_config=None, full_config=None):
    return {
        "train": LazyDataset(datasets_config.train_dataset),
        "val": LazyDataset(datasets_config.val_dataset),
        "test": LazyDataset(datasets_config.test_dataset),
        "predict": LazyDataset(datasets_config.predict_dataset),
    }
```

---

### üü° MEDIUM: WandB Logger Instantiation Before Training

**Location**: `ocr/pipelines/orchestrator.py:157-161`

```python
if hasattr(self.cfg.train, "logger") and self.cfg.train.logger:
    loggers = [
        hydra.utils.instantiate(logger_cfg)  # WandB init HERE
        for logger_cfg in self.cfg.train.logger.values()
    ]
```

**Problem**: WandB logger init involves:
1. Network request to wandb.ai (verify API key)
2. Check for SDK updates
3. Initialize run metadata
4. **All before training starts**

**Impact**: 5-10 seconds (network dependent, worse on WSL)

**Fix**: Conditional instantiation:
```python
def setup_trainer(self):
    trainer_kwargs = {}

    # Only create loggers if actually training (not --help, --cfg, etc.)
    if self.mode == "train" and hasattr(self.cfg.train, "logger"):
        loggers = [hydra.utils.instantiate(cfg) for cfg in self.cfg.train.logger.values()]
        trainer_kwargs["logger"] = loggers
```

---

## WSL-Specific Considerations

### File System Overhead

**Issue**: Cross-mount file access (`/mnt/c/`) adds ~30-50% latency per file operation

**Affected**:
- Dataset scanning (reading image paths from `/mnt/c/data/`)
- Config file loading (if configs on Windows FS)

**Fix**:
```bash
# Move datasets to WSL native filesystem
cp -r /mnt/c/data/datasets /home/user/datasets
# Update config to point to /home/user/datasets
```

**Estimated Savings**: 3-8 seconds for dataset initialization

---

### Python Import Caching

**Issue**: `__pycache__` may not work correctly across WSL/Windows boundary

**Fix**:
```bash
# Force Python to write bytecode cache
export PYTHONDONTWRITEBYTECODE=0

# Clear and regenerate cache
find . -type d -name __pycache__ -exec rm -rf {} +
python -m compileall ocr/
```

---

## Updated Bottleneck Summary

| #   | Bottleneck              | Location                                | Impact | Priority | Fix Effort |
| --- | ----------------------- | --------------------------------------- | ------ | -------- | ---------- |
| 1   | Eager PyTorch import    | `orchestrator.py:9`                     | 8-12s  | üî¥ P0     | 5 min      |
| 2   | Duplicate tokenizer     | `orchestrator.py:53` + `__init__.py:10` | 6-15s  | üî¥ P0     | 10 min     |
| 3   | Eager dataset init      | `datasets/__init__.py:49-51`            | 10-20s | üî¥ P1     | 30 min     |
| 4   | Hydra config resolution | `train.py` + configs                    | 10-20s | üî¥ P1     | 2 hrs      |
| 5   | WandB early init        | `orchestrator.py:157`                   | 5-10s  | üü° P2     | 10 min     |
| 6   | WSL file access         | datasets on `/mnt/c/`                   | 3-8s   | üü° P2     | 1 hr       |
| 7   | torch.compile check     | `base.py:48`                            | 0-20s  | üü° P3     | 5 min      |

**Total Potential Savings**: 42-105 seconds

**Quick Win Target (P0 + P1)**: 34-67 seconds (60-75% reduction)

---

## Immediate Action Items

### 1. Lazy PyTorch Import (5 minutes)

```python
# In orchestrator.py
# REMOVE from top:
# from lightning.pytorch import Trainer

# ADD to setup_trainer():
def setup_trainer(self):
    from lightning.pytorch import Trainer  # Lazy import
    logger.info("‚ö° Configuring Lightning Trainer...")
```

### 2. Cache Tokenizer (10 minutes)

```python
# In orchestrator.py, add method:
def _get_or_create_tokenizer(self):
    """Cache tokenizer to avoid duplicate instantiation."""
    cache_key = '_orchestrator_tokenizer_cache'
    if not hasattr(self.cfg, cache_key):
        import hydra
        setattr(self.cfg, cache_key, hydra.utils.instantiate(self.cfg.data.tokenizer))
    return getattr(self.cfg, cache_key)

# Update _inject_vocab_size() to use it:
def _inject_vocab_size(self):
    tokenizer = self._get_or_create_tokenizer()  # Use cached
    # ... rest
```

### 3. Add Startup Profiler (15 minutes)

```python
# In runners/train.py, add:
import time

class Timer:
    def __init__(self):
        self.start = time.time()
        self.marks = []

    def mark(self, label):
        elapsed = time.time() - self.start
        self.marks.append((label, elapsed))
        print(f"‚è±Ô∏è  {label}: {elapsed:.2f}s")

    def report(self):
        total = time.time() - self.start
        print(f"\n{'='*60}")
        print(f"TOTAL STARTUP TIME: {total:.2f}s")
        for label, t in self.marks:
            print(f"  {label:.<50} {t:.2f}s")
        print(f"{'='*60}\n")

timer = Timer()

@hydra.main(...)
def train(config: DictConfig):
    timer.mark("Hydra config loaded")
    OmegaConf.set_struct(config, False)
    timer.mark("Config struct disabled")
    orchestrator = OCRProjectOrchestrator(config)
    timer.mark("Orchestrator initialized")
    orchestrator.run()
    timer.mark("Training complete")
    timer.report()
```

---

## Verification

Before fixes:
```bash
time python runners/train.py domain=detection --help
# Expected: ~60-90s
```

After P0 fixes (lazy import + tokenizer cache):
```bash
time python runners/train.py domain=detection --help
# Target: ~40-50s (30-40% reduction)
```

After P0+P1 fixes (+ lazy datasets):
```bash
time python runners/train.py domain=detection --help
# Target: ~20-30s (60-70% reduction)
```

---

## Conclusion

The Orchestrator implementation revealed **3 new critical bottlenecks**:
1. Eager PyTorch import (8-12s)
2. Duplicate tokenizer instantiation (6-15s)
3. Eager dataset instantiation (10-20s)

Combined with existing audit findings, total potential savings: **40-100+ seconds**.

**Recommended first actions**:
1. ‚úÖ Implement lazy PyTorch import (5 min, 8-12s savings)
2. ‚úÖ Cache tokenizer (10 min, 6-15s savings)
3. ‚úÖ Add startup profiler (15 min, enables measurement)

These 3 quick fixes should bring startup time from **60-90s** down to **30-50s**, making development significantly more efficient.
