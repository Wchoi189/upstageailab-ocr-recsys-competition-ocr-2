version: 1.0
project: OCR Performance Audit Resolution
status: completed
created: 2026-01-20
completed: 2026-01-20

summary: |
  Detection pipeline fixed from 0.18 it/s to 2.77 it/s (~15x speedup)
  Root cause: GPU sync in loss functions + Pydantic validation defaults
  Hydra v5 compliance: Domain configs use @package _group_ with defaults-based injection

audit_sources:
  - Performance_Audit_OCR_Training_Pipeline_Bottlenecks_1.md
  - Performance_Audit_Supplement_Orchestrator_Findings.md
  - Quick_Win_Performance_Summary.md

phases:
  - name: "Phase 1: Critical Runtime Bottleneck (0.18 â†’ 2.77 it/s)"
    status: completed
    completed_date: 2026-01-20
    priority: P0
    actual_impact: "~15x speedup"
    solution: "Loss function optimization"
    items:
      - name: "BCELoss GPU sync fixes"
        file: ocr/core/models/loss/bce_loss.py
        status: completed
        fix_applied: "validate_inputs=False default, reduced .item() calls"

      - name: "DiceLoss GPU sync fixes"
        file: ocr/core/models/loss/dice_loss.py
        status: completed
        fix_applied: "validate_inputs=False default, removed nan/inf checks"

      - name: "MaskL1Loss GPU sync fix"
        file: ocr/core/models/loss/l1_loss.py
        status: completed
        fix_applied: "Replaced .item() with eps guard"

  - name: "Phase 1b: Hydra v5 Standards Compliance"
    status: completed
    completed_date: 2026-01-20
    priority: P0
    solution: "Domain configs use @package _group_ with defaults-based injection"
    rationale: >
      @package _global_ violates v5 design principles. With @package _group_,
      inline model/data overrides go to _group_ namespace (don't merge).
      Solution: Inject ALL model components via defaults loading separate config files.
    new_files_created:
      - configs/model/loss/db_loss.yaml
      - configs/model/constants/recognition.yaml
    items:
      - name: "Detection domain config"
        file: configs/domain/detection.yaml
        status: completed
        fix_applied: "@package _group_ + load /model/loss/db_loss via defaults"

      - name: "Recognition domain config"
        file: configs/domain/recognition.yaml
        status: completed
        fix_applied: "@package _group_ + load /model/constants/recognition via defaults"

      - name: "PARSeq decoder config"
        file: configs/model/architectures/parseq.yaml
        status: completed
        fix_applied: "Added in_channels, vocab_size interpolation"

      - name: "Recognition dataset config"
        file: configs/data/datasets/recognition.yaml
        status: completed
        fix_applied: "Flattened dataset structure"

  - name: "Phase 2: Startup Time Quick Wins"
    status: deferred
    priority: P1
    reason: "Runtime performance achieved"

  - name: "Phase 3: Dataset/DataLoader Optimization"
    status: deferred
    priority: P2

completed_quick_wins:
  - "BCELoss/DiceLoss/L1Loss GPU sync removal"
  - "Hydra v5 compliant domain configs"

verification_commands:
  detection: "uv run python runners/train.py domain=detection +trainer.fast_dev_run=true"
  recognition: "uv run python runners/train.py domain=recognition +trainer.fast_dev_run=true"

actual_results:
  detection:
    before: 0.18 it/s
    after: 2.77 it/s (steady state)
    improvement: 15.4x
  recognition:
    config: fixed and v5 compliant
    model_loads: true
    note: Dataset not available for runtime test
