ads_version: '2.0'
type: quick_reference
agent: all
tier: 3
priority: high
validates_with: AgentQMS/standards/schemas/compliance-checker.py
compliance_status: unknown
memory_footprint: 350
discovery_trigger:
  keywords:
  - image analysis
  - visual inspection
  - defect detection
  - image quality
  - OCR preprocessing
  - before/after comparison
  - VLM
core_command: "uv run python -m AgentQMS.vlm.cli.analyze_image_defects \\\n  --image\
  \ <path> \\\n  --mode <mode> \\\n  --backend openrouter \\\n  --output-format markdown\
  \ \\\n  --output <output_path>\n"
analysis_modes:
  general_purpose:
    defect: Visual artifacts in output images
    input: Source image characteristics
    compare: Before/after comparisons
    full: Comprehensive multi-mode analysis
  ocr_preprocessing_experiments:
    image_quality: Document quality for OCR (background, slant, shadows, contrast)
    enhancement_validation: Quantify preprocessing effectiveness
    preprocessing_diagnosis: Debug preprocessing failures
  bug_specific:
    bug_001: Inference overlay misalignment analysis
backends:
- name: openrouter
  model: Qwen3 40b
  note: Primary, highest quality
- name: solar_pro2
  note: Alternative API
- name: cli_qwen
  note: Local fallback
configuration:
  config: AgentQMS/vlm/config.yaml
  api_keys: OPENROUTER_API_KEY, SOLAR_PRO2_API_KEY in .env
  prompts: AgentQMS/vlm/prompts/ (markdown/jinja2 templates)
experiment_integration:
  output_location: '{experiment_id}/vlm_reports/'
  intermediate_outputs: '{experiment_id}/outputs/vlm_validation/'
  final_deliverables: '{experiment_id}/artifacts/'
custom_prompts:
  steps:
  - 'Check existing prompts: AgentQMS/vlm/prompts/'
  - Create experiment-specific prompt if needed
  - Prompts can be markdown or jinja2 templates
  - Reference in CLI with --mode or programmatically
via_annotations: 'Include manual annotations: --via-annotations path/to/annotations.json'
usage_pattern:
  baseline_assessment: --mode image_quality on source images
  validation: --mode enhancement_validation on before/after comparisons
  debugging: --mode preprocessing_diagnosis on failures
  evidence_collection: Generate markdown reports for .metadata/assessments/
output_formats:
  markdown: YAML frontmatter + structured content (for EDS artifacts)
  json: Raw structured data
example_workflow:
  assess_baseline: "uv run python -m AgentQMS.vlm.cli.analyze_image_defects \\\n \
    \ --image data/worst_performers/img_001.jpg \\\n  --mode image_quality \\\n  --output\
    \ vlm_reports/baseline_img_001.md\n"
  validate_enhancement: "uv run python -m AgentQMS.vlm.cli.analyze_image_defects \\\
    \n  --image outputs/comparison_img_001.jpg \\\n  --mode enhancement_validation\
    \ \\\n  --output vlm_reports/validation_img_001.md\n"
  diagnose_failure: "uv run python -m AgentQMS.vlm.cli.analyze_image_defects \\\n\
    \  --image outputs/failed_img_005.jpg \\\n  --mode preprocessing_diagnosis \\\n\
    \  --output vlm_reports/diagnosis_img_005.md\n"
key_principle:
  description: VLM tools generate visual evidence for EDS assessments.
  use_cases:
  - Image preprocessing validation
  - Visual defect analysis
  - OCR quality assessment
  - Before/after comparisons
  - Failure investigation requiring visual inspection
id: AG-005
dependencies:
- SC-003
keywords:
- validates
- compliance
- status
- memory
- footprint
- discovery
- trigger
- core
- command
- analysis
fuzzy_threshold: 0.8
